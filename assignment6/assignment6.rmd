---
title: "BSDA: Assignment 6"
author: "Anonymous student"
output: 
  pdf_document: 
    toc: yes
    toc_depth: 1
header-includes:
- \usepackage{float}
- \usepackage{graphicx}
- \usepackage{amsmath}
- \usepackage{relsize}
- \usepackage{cancel}
- \usepackage{booktabs}
editor_options: 
  markdown: 
    wrap: 72
---

# General Information to include

-   **Time used for reading and self-study exercises**: \~ 9 hours.
-   **Time used for the assignment**: \~8 hours
-   **Good with assignment**: Redoing assignment 5 in Stan, it made a little clear the syntax and how to actually use Stan. 
-   **Things to improve in the assignment**: It was really difficult at the beginning to get the syntax right and get everything working. Once I started reading the syntax on binomial_logit and multi_normal it was a little easier to know which types of variables both functions took as input and then I was able to define the data. I would really appreciate some discussion about all the outputs we can get using Stan and their interpretation. I also had issues using RMarkdown and Stan, I have a mac aarch64. I used this solution to fix the issues: [https://discourse.mc-stan.org/t/brms-inside-rmarkdown-r-cmd-shlib-foo-c-fails/17671](https://discourse.mc-stan.org/t/brms-inside-rmarkdown-r-cmd-shlib-foo-c-fails/17671) (installing \texttt{install.packages("StanHeaders")}).
I was getting an error that said something like this:

```{r, eval=FALSE}

> Creating a 'stanmodel' object model Running
> /Library/Frameworks/R.framework/Resources/bin/R CMD SHLIB foo.c 
> Trying to compile a simple C file rmarkdown

>Trying to compile a simple C file using C compiler: â€˜Apple clang version 14.0.0
```

```{r setup, include=FALSE}
# This chunk sets echo = TRUE as default, that is, print all code.
# knitr::opts_chunk$set can be used to set other notebook generation options, too.
# include=FALSE inside curly brackets makes this block not be included in the pdf.
knitr::opts_chunk$set(echo = TRUE)
```

# 1. Generalized linear model: Bioassay with Stan

Replicate the computations for the bioassay example of section 3.7 (BDA3) using Stan.

\newcommand{\vc}[1] { \mathbf{#1} }
\newcommand{\vs}[1] { \boldsymbol{#1} }

## 1. Write down the model for the bioassay data in Stan syntax. For instructions in reporting your implementation, you can refer to parts 2 c) - g) in Assignment 5. More information on the bioassay data can be found in Section 3.7 of the course book. To get access to data, use the following code:

```{r, warning=FALSE, message=FALSE}
library(bsda)
library(rjson)
library(rstan)
library(lubridate)
library(ggplot2)
library(tidyverse)
library(knitr)
library(kableExtra)
library(posterior)
library(bayesplot)
data("bioassay")
```

Use the Gaussian prior
$$
\begin{aligned}
    \begin{bmatrix}
    \alpha \\ \beta
    \end{bmatrix}
    \sim
    \text{N} \left(\vs \mu_0, \vc \Sigma_0 \right), \qquad
    \text{where} \quad
    \vs \mu_0 = \begin{bmatrix} 0 \\ 10 \end{bmatrix} \quad \text{and} \quad
    \vc \Sigma_0 = \begin{bmatrix} 2^2 & 12 \\ 12 & 10^2 \end{bmatrix}.
\end{aligned}
$$
I will first show the model in stan syntax. This model is saved in \texttt{assignment6.stan} which is used later in \texttt{stan()} function.

```{stan, output.var="model"}
data {
  // Biossay Data from BDA3
  int<lower=0> N;
  int<lower=0> y[N];
  vector[N] x;
  int<lower=0> n[N];
  
  // prior data
  vector[2] mu;
  matrix<lower=0>[2, 2] Sigma;
}


parameters {
  // alpha and beta
  vector[2] beta;
}


transformed parameters {
  vector[N] theta = beta[1] + beta[2] * x;
}

model {
  y ~ binomial_logit(n, theta);
  beta ~ multi_normal(mu, Sigma);
}
```

Now using \texttt{stan()} we can sample from the posterior.

```{r}
options(mc.cores = parallel::detectCores())

fit1 <- stan(file = 'assignment6.stan', data = list(
  N = nrow(bioassay),
  y = bioassay$y,
  x = bioassay$x,
  n = bioassay$n,
  mu = c(0, 10),
  Sigma = matrix(c(4, 12, 12, 100), nrow = 2)
), chains=8, seed = 123)

fit1
```


Now I will report my implementation, based on parts 2 c) - g) in Assignment 5:

- The initial points of the MCMC chains are generated randomly by default in Stan. According to the documentation the default is to randomly generate initial values between -2 and 2 on the unconstrained support. The specific initial points randomly chosen for this particular assignment were:

```{r}
inits <- get_inits(fit1)
starting_points <- data.frame(alpha = numeric(0), beta = numeric(0))

for (i in 1:8) {
  alpha <- inits[[i]]$beta[1]
  beta <- inits[[i]]$beta[2]
  
  starting_points <- rbind(starting_points, data.frame(alpha = alpha, beta = beta))
}

knitr::kable(starting_points, format = "latex", 
             booktabs = TRUE, align = "c",linesep = "",
             col.names = c("Alpha",
                           "Beta"),
             caption = "Intial points for each chain") %>%
  kable_styling(latex_options = "HOLD_position")
```

- The number of iterations for each chain (including warmup) is 2,000, which is Stan's default.

- The number of warmup iterations per chain is by default $\frac{\# \text{ iterations}}{2}$, so in this case we have 1,000 warmup iterations.

- The number of chains used were 8, which is the same number of chains I used in assignment 5. Stan uses 4 chains by default but I modified this parameter to 8.

- Figures below display all chains for $\alpha$ and $\beta$ in a single line-plot

```{r}
p <- traceplot(fit1, pars = c('beta[1]', 'beta[2]'), nrow=2) 

p$data <- p$data %>% 
  mutate(parameter = ifelse(parameter=='beta[1]', 'alpha','beta'))
p
```

- Finally here are two tables summarizing the results and showing the MCSEs respectively. Using both of them we can report the posterior statistics of interest by taking into account the MCSEs. We are deciding the digits to report by leaving out digits that are just random noise.

```{r}
df_summary <- summarise_draws(fit1) %>% 
  mutate(variable = case_when(
    variable == 'beta[1]' ~ "alpha",
    variable == 'beta[2]' ~ "beta",
    TRUE ~ variable
  ))

df_summary_mcse <- summarise_draws(fit1, default_mcse_measures()) %>% 
  mutate(variable = case_when(
    variable == 'beta[1]' ~ "alpha",
    variable == 'beta[2]' ~ "beta",
    TRUE ~ variable
  ))

df_summary %>%  kbl(booktabs = T, linesep = "") %>%
  kable_styling(latex_options = c("striped", "scale_down", "HOLD_position")) 

df_summary_mcse %>%  kbl(booktabs = T, linesep = "") %>%
  kable_styling(latex_options = c("striped", "HOLD_position")) 
```

Then we can report the mean and quantiles estimates for $\alpha$ as:

$$
\begin{aligned}
E_{p(\alpha|y)} \left( \alpha\right) =`r format(round(df_summary$mean[1],1), nsmall = 1)` \\
\text{quantiles 5\% and 95\%: } [`r round(df_summary$q5[1],1)`, `r round(df_summary$q95[1],1)`]
\end{aligned}
$$
and  the mean and quantiles estimates for $\beta$ as:

$$
\begin{aligned}
E_{p(\beta|y)} \left( \beta\right) =`r round(df_summary$mean[2],0)`\\
\text{quantiles 5\% and 95\%: } [`r round(df_summary$q5[2],1)`, `r round(df_summary$q95[2],0)`]
\end{aligned}
$$

## 2. Use $\widehat{R}$ for convergence analysis. You can either use Eq. (11.4) in BDA3 or the later version that can be found \href{https://arxiv.org/abs/1903.08008}{\textbf{here}}. You should specify which $\widehat{R}$ you used. In R the best choice is to use function \texttt{Rhat} from package \texttt{rstan} (see \texttt{?rstan::Rhat}). To check $\widehat{R}$ and other diagnostics, you can also call \texttt{monitor(fit)}, where \texttt{fit} is the fit object returned by Stan's sampling function. Report the $\widehat{R}$ values both for $\alpha$ and $\beta$ and discuss the convergence of the chains.

To obtain $\widehat{R}$ which in this case is the maximum of rank normalized split-$\widehat{R}$ and rank normalized folded-split-$\widehat{R}$ we can either use \texttt{rstan::Rhat()} function which requires a two-dimensional array whose rows are equal to the number of iterations of the Markov Chains and whose columns are equal to the number of Markov Chains or we can extract $\widehat{R}$ directly from the inference summary of our Stan model, both paths should give us the same answer.

```{r}
sample <- rstan::extract(fit1, permuted=FALSE)
df_summary_conv <- summarise_draws(fit1, default_convergence_measures()) %>% 
  mutate(variable = case_when(
    variable == 'beta[1]' ~ "alpha",
    variable == 'beta[2]' ~ "beta",
    TRUE ~ variable
  ))

# Rhat Alpha
rstan::Rhat(sample[,,1])
df_summary_conv$rhat[1]


# Rhat Beta
rstan::Rhat(sample[,,2])
df_summary_conv$rhat[2]


df_summary_conv %>%  kbl(booktabs = T, linesep = "") %>%
  kable_styling(latex_options = c("striped", "HOLD_position"))
```

Having an $\widehat{R} = 1$ means that the between and within variance in our simulated sequences is the same and that our chains are mixed and have converged. in this case we obtained values for $\alpha$ and $\beta$ pretty close to 1, specifically we got: `r round(df_summary_conv$rhat[1],3)`, and `r round(df_summary_conv$rhat[2], 3)` respectively meaning that the between and within chain variance are about equal. According to  \texttt{rstan::Rhat} documentation the convention is that if $\widehat{R}$ is big (e.g., $\widehat{R} > 1.05$) we should keep sampling, in this case both values are less than 1.05 and greater than 1, indicating that the chains have converged and mixed. 

## Plot the draws for $\alpha$ and $\beta$ (scatter plot) and include this plot in your report. You can compare the results to Figure~3.3b in BDA3 to verify that your code gives sensible results. Notice though that the results in Figure~3.3b are generated from posterior with a uniform prior, so even when your algorithm works perfectly, the results will look slightly different (although fairly similar).

The figure below is a scatter plot showing the the draws from the posterior for $\alpha$ and $\beta$. 

```{r}
p1 <- mcmc_scatter(fit1, pars = c("beta[1]", "beta[2]"), size = 1, alpha = 0.25)

p1 + stat_density_2d(color = "black", linewidth = .5) +
  labs(y = "beta", x = "alpha")
```


